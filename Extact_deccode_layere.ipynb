{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extact_deccode_layere.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMs1vM13djEjK4F/1P0SQwj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hereagain-Y/test-only/blob/main/Extact_deccode_layere.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bQZSQr2aCMEh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "from six.moves import xrange\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-dgwmf5CRag",
        "outputId": "86975523-d383-49b1-c43f-0976eb65ca9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = True\n",
        "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "batch_size = 1000\n",
        "\n",
        "x_dim=114 # 19*6\n",
        "hidden_dim = 100\n",
        "#hidden_dim2 = \n",
        "\n",
        "latent_dim = 64\n",
        "\n",
        "lr = 1e-3\n",
        "\n",
        "epochs = 500"
      ],
      "metadata": {
        "id": "eVycpnD8CVzp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Encoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.FC_input = nn.Linear(input_dim, hidden_dim)\n",
        "        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        #self.FC_input3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.FC_mean  = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.FC_var   = nn.Linear (hidden_dim, latent_dim)\n",
        "        \n",
        "       # self.LeakyReLU = nn.LeakyReLU(0.2)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        self.training = True\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h_       = self.relu(self.FC_input(x))\n",
        "        h_       = self.relu(self.FC_input2(h_))\n",
        "        #h_       = self.relu(self.FC_input3(h_))\n",
        "        mean     = self.FC_mean(h_)\n",
        "        log_var  = self.FC_var(h_)                     # encoder produces mean and log of variance \n",
        "                                                     #             (i.e., parateters of simple tractable normal distribution \"q\"\n",
        "        \n",
        "        return mean, log_var\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim,output_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.FC_hidden = nn.Linear(latent_dim, hidden_dim)\n",
        "        #self.FC_hidden3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.FC_output = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h     = self.relu(self.FC_hidden(x))\n",
        "        #h     = self.relu(self.FC_hidden3(h))\n",
        "        h     = self.relu(self.FC_hidden2(h))\n",
        "        #x_hat = torch.sigmoid(self.FC_output(h))\n",
        "        x_hat = self.relu(self.FC_output(h))\n",
        "        \n",
        "        #x_hat = torch.sigmoid(self.FC_output(h))\n",
        "        return x_hat\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, Encoder, Decoder):\n",
        "        super(Model, self).__init__()\n",
        "        self.Encoder = Encoder\n",
        "        self.Decoder = Decoder\n",
        "        \n",
        "    def reparameterization(self, mean, var):\n",
        "        #epsilon = torch.randn_like(var).to(DEVICE)        # sampling epsilon        \n",
        "        #z = mean + var*epsilon \n",
        "        z  = mean                       # reparameterization trick\n",
        "        return z\n",
        "        \n",
        "                \n",
        "    def forward(self, x):\n",
        "        mean, log_var = self.Encoder(x)\n",
        "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var) ]\n",
        "        x_hat            = self.Decoder(z)\n",
        "        \n",
        "        return x_hat, mean, log_var\n",
        "\n",
        "encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim,  latent_dim=latent_dim)\n",
        "decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n",
        "\n",
        "model = Model(Encoder=encoder, Decoder=decoder).to(DEVICE)"
      ],
      "metadata": {
        "id": "lbwmrRQaCaXI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('/content/drive/My Drive/DL/VAE/Newdata/NewPCA_VAE_modify_MSE_model_10000_echo.apx')"
      ],
      "metadata": {
        "id": "tG5cdb7hCjsx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_test = pd.read_csv(\"/content/drive/My Drive/DL/VAE/NormalCDR3_test.txt\", delimiter='\\t',header=None,names=['seq'])"
      ],
      "metadata": {
        "id": "7ntQK-1bCp-D"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_test['length'] = [len(seq) for seq in seq_test['seq']]\n",
        "\n",
        "seq_test = seq_test[ seq_test['length']<=20 ]\n",
        "seq = list( seq_test['seq'] )\n"
      ],
      "metadata": {
        "id": "oR3-cqUYC9P_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d= {} # bipphysics dictionary\n",
        "with open(\"/content/drive/My Drive/DL/VAE/Newdata/PC1-6_index.txt\") as f:\n",
        "    next(f)\n",
        "    for line in f.readlines():\n",
        "        line=line.strip().split('\\t') #\n",
        "        AA=line[0]\n",
        "        tag=0\n",
        "        values=[]\n",
        "        for PC in line[1:]:\n",
        "            values.append(float(PC))\n",
        "        if tag==1: \n",
        "            continue\n",
        "        d[AA]=values\n"
      ],
      "metadata": {
        "id": "qdyFAAidDDBg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AAs= ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
        "d=dict(zip(AAs,list(d.values())))"
      ],
      "metadata": {
        "id": "l0NZy7WMDP9C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def AAindexEncoding(Seq):\n",
        "    length_seq=len(Seq)\n",
        "    global max_len\n",
        "    AAE=np.zeros([19,6])\n",
        "    if length_seq<19:\n",
        "        for amino in range(length_seq):\n",
        "            AA=Seq[amino]# \n",
        "            AAE[amino,]=d[AA] # add PC value \n",
        "            \n",
        "        for amino in range(length_seq,19):\n",
        "            AAE[amino,]=np.zeros(6)\n",
        "    else: \n",
        "        for amino in range(length_seq): # zero padding\n",
        "            AA=Seq[amino]# \n",
        "            AAE[amino,]=d[AA]\n",
        "        \n",
        "    #AAE=np.transpose(AAE.astype(np.float32)) # row as PC. and column as AA sequence \n",
        "    return AAE \n",
        "  \n",
        "def GetFeatures(file):\n",
        "    #sequence=file['amino_acid'].tolist()\n",
        "    #sequence=np.array(sequence)\n",
        "    #sequence = file.read().splitlines()\n",
        "    #sequence=np.array(sequence)\n",
        "    hot_encode=[]\n",
        "    for seq in file:\n",
        "        hot_encode.append(AAindexEncoding(seq))\n",
        "    hot_encode=np.array(hot_encode)\n",
        "    result=np.array(hot_encode)\n",
        "    return(result) # dimension: number of sequence [15*length(sequence)]\n",
        "\n",
        "r1=GetFeatures(seq)"
      ],
      "metadata": {
        "id": "6OIA57B7DUjJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get encode layer "
      ],
      "metadata": {
        "id": "JbXdonP7DlF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r1_transform=torch.from_numpy(r1).float() # change to tensor and float \n",
        "m2=r1_transform.view(len(r1_transform),114) # flatten \n",
        "#m2 = torch.from_numpy(m2).float()\n",
        "#result = model(m2)[0] # m\n",
        "#result = model(m2.cuda())[0]#\n",
        "#result2 = result.view( len(result),19,6 ).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "6SdTxGabDkq3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(m2.cuda())[0].size() #19851 *114"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLTs5hfHEJ1V",
        "outputId": "dc0c9174-06be-437e-8f58-5c3b98ce29cc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19851, 114])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(m2.cuda())[1].size()  # 64 latent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZwyvF2REZTK",
        "outputId": "7ad9dec6-50cd-4e7f-8276-92ff55681bc5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19851, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(m2.cuda())[2].size() # 19851*64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTMNnWYDEcGI",
        "outputId": "1d181252-840d-498e-d7bd-a2be24cd0ad3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19851, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inter= model.Encoder(m2.cuda()) # use the encode layer"
      ],
      "metadata": {
        "id": "lfmuf9hrEhG8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1=inter[0]# latent mean layer"
      ],
      "metadata": {
        "id": "GNB743GJF0dJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.Decoder(m1).size() # decode to orginal dimension "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5TczRsMGO-k",
        "outputId": "a710d073-b8e7-40c8-8e6a-91036697a99d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19851, 114])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(m2.cuda())[1] #. exacltly same as m1 model.Encoder(m2.cuda()) [0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ9b7OV6G5BT",
        "outputId": "ebab9139-c82b-4dea-b8e1-c044775ddcbf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.7977e-05,  6.8177e-06, -4.0675e-05,  ..., -3.6227e-04,\n",
              "         -5.8922e-05,  3.6709e-05],\n",
              "        [ 4.8089e-05,  6.7758e-06, -4.0291e-05,  ..., -3.4761e-04,\n",
              "         -5.8473e-05,  3.6405e-05],\n",
              "        [ 4.7965e-05,  6.5775e-06, -4.0668e-05,  ..., -3.3977e-04,\n",
              "         -5.8597e-05,  3.6286e-05],\n",
              "        ...,\n",
              "        [ 5.1204e-05,  8.8991e-06, -4.1294e-05,  ...,  6.0574e-04,\n",
              "         -5.6253e-05,  1.3266e-05],\n",
              "        [ 5.0246e-05,  8.1521e-06, -4.1348e-05,  ...,  3.5192e-04,\n",
              "         -5.6972e-05,  1.9486e-05],\n",
              "        [ 5.0212e-05,  8.3799e-06, -4.1795e-05,  ...,  3.4880e-04,\n",
              "         -5.7575e-05,  1.9440e-05]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(m2.cuda())[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReOEli2gHJFV",
        "outputId": "f32f1bd6-9aa2-448e-f0ad-e83a955b1651"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.4608e-05,  1.9589e-05,  5.9137e-08,  ..., -3.9671e-08,\n",
              "         -3.1551e-06,  1.1839e-08],\n",
              "        [-2.4544e-05,  1.9856e-05,  5.9608e-08,  ..., -3.9932e-08,\n",
              "         -3.1597e-06,  9.4138e-09],\n",
              "        [-2.4716e-05,  1.9979e-05,  5.9292e-08,  ..., -3.9812e-08,\n",
              "         -3.1703e-06,  1.1567e-08],\n",
              "        ...,\n",
              "        [-2.4881e-05,  2.0466e-05,  7.4047e-08,  ..., -5.2987e-08,\n",
              "         -3.3125e-06,  1.7405e-08],\n",
              "        [-2.4936e-05,  2.0399e-05,  6.9830e-08,  ..., -4.9317e-08,\n",
              "         -3.2797e-06,  1.7100e-08],\n",
              "        [-2.4957e-05,  1.9918e-05,  6.9611e-08,  ..., -4.9298e-08,\n",
              "         -3.2707e-06,  2.0084e-08]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.Decoder(m1).size() # 114 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YFCOEjHHOqR",
        "outputId": "360188f4-aa6d-4071-bd7e-4d71f6acaa7e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19851, 114])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}